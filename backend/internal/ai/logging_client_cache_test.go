package ai

import (
	"context"
	"os"
	"testing"
	"time"

	"backend/internal/cache"
	modelspkg "backend/internal/models"
)

// mockModelClient æ¨¡æ‹Ÿçš„AIå®¢æˆ·ç«¯
type mockModelClient struct {
	callCount int // è®°å½•å®é™…APIè°ƒç”¨æ¬¡æ•°
}

func (m *mockModelClient) ChatCompletion(ctx context.Context, req *ChatCompletionRequest) (*ChatCompletionResponse, error) {
	m.callCount++
	
	// æ¨¡æ‹ŸAPIå»¶è¿Ÿ
	time.Sleep(100 * time.Millisecond)
	
	return &ChatCompletionResponse{
		ID:      "mock-response-id",
		Model:   "gpt-3.5-turbo",
		Content: "This is a mock response for: " + req.Messages[0].Content,
		Usage: Usage{
			PromptTokens:     10,
			CompletionTokens: 20,
			TotalTokens:      30,
		},
	}, nil
}

func (m *mockModelClient) ChatCompletionStream(ctx context.Context, req *ChatCompletionRequest) (<-chan StreamChunk, <-chan error) {
	return nil, nil
}

func (m *mockModelClient) Embedding(ctx context.Context, req *EmbeddingRequest) (*EmbeddingResponse, error) {
	return nil, nil
}

func (m *mockModelClient) Name() string {
	return "mock"
}

func (m *mockModelClient) Close() error {
	return nil
}

// TestLoggingClientCache æµ‹è¯•ç¼“å­˜åŠŸèƒ½
func TestLoggingClientCache(t *testing.T) {
	// åˆ›å»ºä¸´æ—¶æ•°æ®åº“æ–‡ä»¶
	tempDB := "./test_cache.db"
	defer os.Remove(tempDB)
	
	// åˆå§‹åŒ–ç¡¬ç›˜ç¼“å­˜
	diskCache, err := cache.NewDiskCache(tempDB, 1*time.Hour, 1)
	if err != nil {
		t.Fatalf("åˆ›å»ºDiskCacheå¤±è´¥: %v", err)
	}
	defer diskCache.Close()
	
	// åˆ›å»ºmockå®¢æˆ·ç«¯
	mockClient := &mockModelClient{}
	
	// åˆ›å»ºLoggingClientï¼ˆå¸¦ç¼“å­˜ï¼‰
	model := &modelspkg.Model{
		ID:               "test-model",
		Name:             "Test Model",
		Provider:         "openai",
		ModelIdentifier:  "gpt-3.5-turbo",
		InputCostPer1K:   0.001,
		OutputCostPer1K:  0.002,
	}
	
	loggingClient := NewLoggingClient(mockClient, nil, "tenant-1", "model-1", model, diskCache)
	
	// æ„å»ºæµ‹è¯•è¯·æ±‚ï¼ˆä½æ¸©åº¦ï¼Œå¯ç¼“å­˜ï¼‰
	req := &ChatCompletionRequest{
		Messages: []Message{
			{Role: "user", Content: "Hello, world!"},
		},
		Temperature: 0.1, // ä½æ¸©åº¦ï¼Œå¯ç”¨ç¼“å­˜
		MaxTokens:   100,
		TopP:        0.9,
	}
	
	ctx := context.Background()
	
	// ç¬¬ä¸€æ¬¡è°ƒç”¨ - åº”è¯¥å‘½ä¸­API
	t.Log("ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆåº”è¯¥è°ƒç”¨å®é™…APIï¼‰...")
	start1 := time.Now()
	resp1, err := loggingClient.ChatCompletion(ctx, req)
	latency1 := time.Since(start1).Milliseconds()
	
	if err != nil {
		t.Fatalf("ç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	if resp1 == nil {
		t.Fatal("å“åº”ä¸ºç©º")
	}
	if mockClient.callCount != 1 {
		t.Fatalf("æœŸæœ›APIè°ƒç”¨æ¬¡æ•°ä¸º1ï¼Œå®é™…ä¸º%d", mockClient.callCount)
	}
	t.Logf("âœ… ç¬¬ä¸€æ¬¡è°ƒç”¨æˆåŠŸ - å»¶è¿Ÿ: %dms, APIè°ƒç”¨æ¬¡æ•°: %d", latency1, mockClient.callCount)
	
	// ç­‰å¾…ç¼“å­˜å†™å…¥å®Œæˆï¼ˆå¼‚æ­¥å†™å…¥ï¼‰
	time.Sleep(200 * time.Millisecond)
	
	// ç¬¬äºŒæ¬¡è°ƒç”¨ - åº”è¯¥å‘½ä¸­ç¼“å­˜
	t.Log("ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰...")
	start2 := time.Now()
	resp2, err := loggingClient.ChatCompletion(ctx, req)
	latency2 := time.Since(start2).Milliseconds()
	
	if err != nil {
		t.Fatalf("ç¬¬äºŒæ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	if resp2 == nil {
		t.Fatal("ç¼“å­˜å“åº”ä¸ºç©º")
	}
	if mockClient.callCount != 1 {
		t.Fatalf("æœŸæœ›APIè°ƒç”¨æ¬¡æ•°ä»ä¸º1ï¼ˆå‘½ä¸­ç¼“å­˜ï¼‰ï¼Œå®é™…ä¸º%d", mockClient.callCount)
	}
	
	// éªŒè¯ç¼“å­˜å“åº”ä¸åŸå§‹å“åº”ç›¸åŒ
	if resp2.Content != resp1.Content {
		t.Fatalf("ç¼“å­˜å“åº”å†…å®¹ä¸ä¸€è‡´: æœŸæœ› %s, å®é™… %s", resp1.Content, resp2.Content)
	}
	
	// ç¼“å­˜å‘½ä¸­åº”è¯¥æ˜¾è‘—å¿«äºç¬¬ä¸€æ¬¡è°ƒç”¨
	if latency2 >= latency1 {
		t.Logf("âš ï¸  ç¼“å­˜å»¶è¿Ÿ(%dms)æœªæ˜æ˜¾ä½äºAPIå»¶è¿Ÿ(%dms) - å¯èƒ½ç¼“å­˜æŸ¥è¯¢è¾ƒæ…¢", latency2, latency1)
	} else {
		t.Logf("âœ… ç¬¬äºŒæ¬¡è°ƒç”¨å‘½ä¸­ç¼“å­˜ - å»¶è¿Ÿ: %dms (æé€Ÿ%.1fx), APIè°ƒç”¨æ¬¡æ•°: %d",
			latency2, float64(latency1)/float64(latency2), mockClient.callCount)
	}
	
	// ç¬¬ä¸‰æ¬¡è°ƒç”¨ä¸åŒå†…å®¹ - åº”è¯¥æœªå‘½ä¸­ç¼“å­˜
	t.Log("ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼ˆä¸åŒå†…å®¹ï¼Œåº”è¯¥æœªå‘½ä¸­ç¼“å­˜ï¼‰...")
	req3 := &ChatCompletionRequest{
		Messages: []Message{
			{Role: "user", Content: "Different message"},
		},
		Temperature: 0.1,
		MaxTokens:   100,
		TopP:        0.9,
	}
	
	resp3, err := loggingClient.ChatCompletion(ctx, req3)
	if err != nil {
		t.Fatalf("ç¬¬ä¸‰æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	if resp3 == nil {
		t.Fatal("ç¬¬ä¸‰æ¬¡å“åº”ä¸ºç©º")
	}
	if mockClient.callCount != 2 {
		t.Fatalf("æœŸæœ›APIè°ƒç”¨æ¬¡æ•°ä¸º2ï¼Œå®é™…ä¸º%d", mockClient.callCount)
	}
	t.Logf("âœ… ç¬¬ä¸‰æ¬¡è°ƒç”¨æˆåŠŸï¼ˆä¸åŒå†…å®¹ï¼‰ - APIè°ƒç”¨æ¬¡æ•°: %d", mockClient.callCount)
	
	// æµ‹è¯•é«˜æ¸©åº¦è¯·æ±‚ï¼ˆä¸åº”ä½¿ç”¨ç¼“å­˜ï¼‰
	t.Log("ç¬¬å››æ¬¡è°ƒç”¨ï¼ˆé«˜æ¸©åº¦ï¼Œä¸åº”ä½¿ç”¨ç¼“å­˜ï¼‰...")
	req4 := &ChatCompletionRequest{
		Messages: []Message{
			{Role: "user", Content: "Hello, world!"}, // ç›¸åŒå†…å®¹
		},
		Temperature: 0.8, // é«˜æ¸©åº¦ï¼Œä¸å¯ç”¨ç¼“å­˜
		MaxTokens:   100,
		TopP:        0.9,
	}
	
	resp4, err := loggingClient.ChatCompletion(ctx, req4)
	if err != nil {
		t.Fatalf("ç¬¬å››æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	if resp4 == nil {
		t.Fatal("ç¬¬å››æ¬¡å“åº”ä¸ºç©º")
	}
	if mockClient.callCount != 3 {
		t.Fatalf("æœŸæœ›APIè°ƒç”¨æ¬¡æ•°ä¸º3ï¼ˆé«˜æ¸©åº¦ä¸ç¼“å­˜ï¼‰ï¼Œå®é™…ä¸º%d", mockClient.callCount)
	}
	t.Logf("âœ… ç¬¬å››æ¬¡è°ƒç”¨æˆåŠŸï¼ˆé«˜æ¸©åº¦ï¼‰ - APIè°ƒç”¨æ¬¡æ•°: %d", mockClient.callCount)
	
	t.Log("ğŸ‰ æ‰€æœ‰ç¼“å­˜æµ‹è¯•é€šè¿‡ï¼")
}

// TestLoggingClient_GetCacheStats æµ‹è¯•ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½
func TestLoggingClient_GetCacheStats(t *testing.T) {
	// åˆ›å»ºä¸´æ—¶æ•°æ®åº“æ–‡ä»¶
	tempDB := ":memory:" // ä½¿ç”¨å†…å­˜æ•°æ®åº“ï¼Œæ— éœ€æ¸…ç†
	
	// åˆå§‹åŒ–ç¡¬ç›˜ç¼“å­˜
	diskCache, err := cache.NewDiskCache(tempDB, 1*time.Hour, 1)
	if err != nil {
		t.Fatalf("åˆ›å»ºDiskCacheå¤±è´¥: %v", err)
	}
	defer diskCache.Close()
	
	// åˆ›å»ºmockå®¢æˆ·ç«¯
	mockClient := &mockModelClient{}
	
	// åˆ›å»ºLoggingClientï¼ˆå¸¦ç¼“å­˜ï¼‰
	model := &modelspkg.Model{
		ID:              "test-model",
		Provider:        "openai",
		ModelIdentifier: "gpt-3.5-turbo",
		InputCostPer1K:  0.001,
		OutputCostPer1K: 0.002,
	}
	
	loggingClient := NewLoggingClient(mockClient, nil, "tenant-1", "model-1", model, diskCache)
	
	ctx := context.Background()
	
	// æµ‹è¯•åˆå§‹çŠ¶æ€
	t.Log("æµ‹è¯•åˆå§‹çŠ¶æ€...")
	stats := loggingClient.GetCacheStats()
	if stats["cache_hits"].(int64) != 0 {
		t.Errorf("åˆå§‹cache_hitsåº”ä¸º0ï¼Œå®é™…: %v", stats["cache_hits"])
	}
	if stats["cache_misses"].(int64) != 0 {
		t.Errorf("åˆå§‹cache_missesåº”ä¸º0ï¼Œå®é™…: %v", stats["cache_misses"])
	}
	if stats["total_requests"].(int64) != 0 {
		t.Errorf("åˆå§‹total_requestsåº”ä¸º0ï¼Œå®é™…: %v", stats["total_requests"])
	}
	if stats["hit_rate_percent"].(float64) != 0.0 {
		t.Errorf("åˆå§‹hit_rate_percentåº”ä¸º0.0ï¼Œå®é™…: %v", stats["hit_rate_percent"])
	}
	if stats["cache_enabled"].(bool) != true {
		t.Errorf("cache_enabledåº”ä¸ºtrueï¼Œå®é™…: %v", stats["cache_enabled"])
	}
	t.Logf("âœ… åˆå§‹çŠ¶æ€æ­£ç¡®: %+v", stats)
	
	// æ„å»ºæµ‹è¯•è¯·æ±‚ï¼ˆä½æ¸©åº¦ï¼Œå¯ç¼“å­˜ï¼‰
	req := &ChatCompletionRequest{
		Messages: []Message{
			{Role: "user", Content: "Hello, world!"},
		},
		Temperature: 0.1,
		MaxTokens:   100,
		TopP:        0.9,
	}
	
	// ç¬¬ä¸€æ¬¡è°ƒç”¨ - ç¼“å­˜æœªå‘½ä¸­
	t.Log("ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆåº”è¯¥ç¼“å­˜æœªå‘½ä¸­ï¼‰...")
	_, err = loggingClient.ChatCompletion(ctx, req)
	if err != nil {
		t.Fatalf("ç¬¬ä¸€æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	
	// ç­‰å¾…ç¼“å­˜å†™å…¥
	time.Sleep(200 * time.Millisecond)
	
	stats = loggingClient.GetCacheStats()
	if stats["cache_hits"].(int64) != 0 {
		t.Errorf("ç¬¬ä¸€æ¬¡åcache_hitsåº”ä¸º0ï¼Œå®é™…: %v", stats["cache_hits"])
	}
	if stats["cache_misses"].(int64) != 1 {
		t.Errorf("ç¬¬ä¸€æ¬¡åcache_missesåº”ä¸º1ï¼Œå®é™…: %v", stats["cache_misses"])
	}
	if stats["total_requests"].(int64) != 1 {
		t.Errorf("ç¬¬ä¸€æ¬¡åtotal_requestsåº”ä¸º1ï¼Œå®é™…: %v", stats["total_requests"])
	}
	if stats["hit_rate_percent"].(float64) != 0.0 {
		t.Errorf("ç¬¬ä¸€æ¬¡åhit_rate_percentåº”ä¸º0.0ï¼Œå®é™…: %v", stats["hit_rate_percent"])
	}
	t.Logf("âœ… ç¬¬ä¸€æ¬¡è°ƒç”¨ç»Ÿè®¡æ­£ç¡®: %+v", stats)
	
	// ç¬¬äºŒæ¬¡è°ƒç”¨ - ç¼“å­˜å‘½ä¸­
	t.Log("ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥ç¼“å­˜å‘½ä¸­ï¼‰...")
	_, err = loggingClient.ChatCompletion(ctx, req)
	if err != nil {
		t.Fatalf("ç¬¬äºŒæ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	
	stats = loggingClient.GetCacheStats()
	if stats["cache_hits"].(int64) != 1 {
		t.Errorf("ç¬¬äºŒæ¬¡åcache_hitsåº”ä¸º1ï¼Œå®é™…: %v", stats["cache_hits"])
	}
	if stats["cache_misses"].(int64) != 1 {
		t.Errorf("ç¬¬äºŒæ¬¡åcache_missesåº”ä¸º1ï¼Œå®é™…: %v", stats["cache_misses"])
	}
	if stats["total_requests"].(int64) != 2 {
		t.Errorf("ç¬¬äºŒæ¬¡åtotal_requestsåº”ä¸º2ï¼Œå®é™…: %v", stats["total_requests"])
	}
	if stats["hit_rate_percent"].(float64) != 50.0 {
		t.Errorf("ç¬¬äºŒæ¬¡åhit_rate_percentåº”ä¸º50.0ï¼Œå®é™…: %v", stats["hit_rate_percent"])
	}
	t.Logf("âœ… ç¬¬äºŒæ¬¡è°ƒç”¨ç»Ÿè®¡æ­£ç¡®: %+v", stats)
	
	// ç¬¬ä¸‰æ¬¡è°ƒç”¨ - å†æ¬¡ç¼“å­˜å‘½ä¸­
	t.Log("ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼ˆåº”è¯¥å†æ¬¡ç¼“å­˜å‘½ä¸­ï¼‰...")
	_, err = loggingClient.ChatCompletion(ctx, req)
	if err != nil {
		t.Fatalf("ç¬¬ä¸‰æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	
	stats = loggingClient.GetCacheStats()
	if stats["cache_hits"].(int64) != 2 {
		t.Errorf("ç¬¬ä¸‰æ¬¡åcache_hitsåº”ä¸º2ï¼Œå®é™…: %v", stats["cache_hits"])
	}
	if stats["cache_misses"].(int64) != 1 {
		t.Errorf("ç¬¬ä¸‰æ¬¡åcache_missesåº”ä¸º1ï¼Œå®é™…: %v", stats["cache_misses"])
	}
	if stats["total_requests"].(int64) != 3 {
		t.Errorf("ç¬¬ä¸‰æ¬¡åtotal_requestsåº”ä¸º3ï¼Œå®é™…: %v", stats["total_requests"])
	}
	// å…è®¸æµ®ç‚¹æ•°è¯¯å·®
	hitRate := stats["hit_rate_percent"].(float64)
	expectedHitRate := 66.66666666666667
	if hitRate < expectedHitRate-0.01 || hitRate > expectedHitRate+0.01 {
		t.Errorf("ç¬¬ä¸‰æ¬¡åhit_rate_percentåº”çº¦ä¸º66.67ï¼Œå®é™…: %v", hitRate)
	}
	t.Logf("âœ… ç¬¬ä¸‰æ¬¡è°ƒç”¨ç»Ÿè®¡æ­£ç¡®: %+v", stats)
	
	// ç¬¬å››æ¬¡è°ƒç”¨ - ä¸åŒå†…å®¹ï¼Œç¼“å­˜æœªå‘½ä¸­
	t.Log("ç¬¬å››æ¬¡è°ƒç”¨ï¼ˆä¸åŒå†…å®¹ï¼Œåº”è¯¥ç¼“å­˜æœªå‘½ä¸­ï¼‰...")
	req2 := &ChatCompletionRequest{
		Messages: []Message{
			{Role: "user", Content: "Different message"},
		},
		Temperature: 0.1,
		MaxTokens:   100,
		TopP:        0.9,
	}
	
	_, err = loggingClient.ChatCompletion(ctx, req2)
	if err != nil {
		t.Fatalf("ç¬¬å››æ¬¡è°ƒç”¨å¤±è´¥: %v", err)
	}
	
	stats = loggingClient.GetCacheStats()
	if stats["cache_hits"].(int64) != 2 {
		t.Errorf("ç¬¬å››æ¬¡åcache_hitsåº”ä¸º2ï¼Œå®é™…: %v", stats["cache_hits"])
	}
	if stats["cache_misses"].(int64) != 2 {
		t.Errorf("ç¬¬å››æ¬¡åcache_missesåº”ä¸º2ï¼Œå®é™…: %v", stats["cache_misses"])
	}
	if stats["total_requests"].(int64) != 4 {
		t.Errorf("ç¬¬å››æ¬¡åtotal_requestsåº”ä¸º4ï¼Œå®é™…: %v", stats["total_requests"])
	}
	if stats["hit_rate_percent"].(float64) != 50.0 {
		t.Errorf("ç¬¬å››æ¬¡åhit_rate_percentåº”ä¸º50.0ï¼Œå®é™…: %v", stats["hit_rate_percent"])
	}
	t.Logf("âœ… ç¬¬å››æ¬¡è°ƒç”¨ç»Ÿè®¡æ­£ç¡®: %+v", stats)
	
	t.Log("ğŸ‰ æ‰€æœ‰ç¼“å­˜ç»Ÿè®¡æµ‹è¯•é€šè¿‡ï¼")
}

// TestLoggingClient_GetCacheStats_NoCache æµ‹è¯•æ— ç¼“å­˜æ—¶çš„ç»Ÿè®¡
func TestLoggingClient_GetCacheStats_NoCache(t *testing.T) {
	mockClient := &mockModelClient{}
	
	// åˆ›å»ºLoggingClientï¼ˆä¸å¯ç”¨ç¼“å­˜ï¼‰
	loggingClient := NewLoggingClient(mockClient, nil, "tenant-1", "model-1", nil, nil)
	
	stats := loggingClient.GetCacheStats()
	if stats["cache_enabled"].(bool) != false {
		t.Errorf("æ— ç¼“å­˜æ—¶cache_enabledåº”ä¸ºfalseï¼Œå®é™…: %v", stats["cache_enabled"])
	}
	if stats["total_requests"].(int64) != 0 {
		t.Errorf("æ— ç¼“å­˜æ—¶total_requestsåº”ä¸º0ï¼Œå®é™…: %v", stats["total_requests"])
	}
	
	t.Logf("âœ… æ— ç¼“å­˜ç»Ÿè®¡æ­£ç¡®: %+v", stats)
}
