## 需求拆解
1. **模型接入能力评估**：确认现有 `models` 表字段是否足够支撑 OpenAI/Gemini/自定义供应商接入；若不足需列出新增字段（如凭证、区域、速率限制、模型别名等）。
2. **模型列表服务**：梳理后端 API（Service + Handler）以 <100ms 为目标提供分页/过滤/缓存策略，并评估需要的索引或缓存层。
3. **终端用户自助接入**：定义用户可配置的“API Key/Endpoint”存储方案（可能新建 `model_credentials` 或在 `models` 补充 `auth_config`），考虑安全加密与多租户隔离。
4. **Agent 默认模型与自动降级**：为 agent 配置主副模型（表/字段设计 + 服务逻辑 + fallback 流程），触发条件（超时/异常/不可用），以及监控记录。
5. **前端展示与交互**：规划模型列表 UI、模型状态及 agent 默认/备选模型选择器，并在前端反馈降级状态。

## 拟定方案
1. **数据库层**
   - 在 `models` 表保留通用字段，补充：`region`、`rate_limit`、`latency_slo_ms`、`metadata`（JSONB，用于 provider-specific 信息）。
   - 新增 `model_credentials` 表：`id`, `tenant_id`, `model_id`, `provider`, `api_key_encrypted`, `base_url`, `extra_headers`, `created_by`, `status`，确保加密存储与 KMS 集成预留。
   - 为 agent 配置表（若现有 `agents` 表）新增 `primary_model_id`, `secondary_model_id`, `fallback_strategy`，并创建联合索引。

2. **后端服务**
   - 扩展 ModelService：支持三大 provider 的校验逻辑、凭证管理 CRUD、模型列表缓存（Redis 或本地 LRU）+ 分页查询优化（SELECT 列表 + covering index）。
   - 实现 `ModelDiscovery` 聚合器：统一返回 openai/gemini/api 接口列表，缓存 60s，保证 100ms SLA（缓存命中 + 并发 fetch）。
   - AgentRuntime：在执行前先探测主模型可用性（健康缓存 + token 余额），失败即自动切换 secondary，并记录在 `model_call_logs`。
   - 增加 `model_health` 定时探测任务，维护状态供降级判断。

3. **前端**
   - 新增“模型管理”页面：列表（provider、类型、延迟、状态、使用数）、创建/编辑弹窗（API Key、Base URL、模型选择）。
   - Agent 配置界面增加主/备模型下拉、多状态提示（当前使用、降级中）。
   - 状态 Banner：当发生降级时在对应 Agent 工作流 UI 弹出提示。

4. **性能与监控**
   - 通过 GORM 预加载 + Redis 缓存保障列表查询 <100ms；必要时在 handler 层增加 fast-path（仅查询 active models）。
   - 在 `ModelCallLog` 记录 `fallback_used`、`error_type` 等字段，便于追踪；暴露 Prometheus 指标（model_latency, fallback_count）。

5. **安全**
   - API 密钥使用 KMS/Hashicorp Vault 加密；后端调用请求时才解密。
   - 限制用户对模型凭证的访问权限，提供审计日志。

确认以上设计后，可进入实现阶段。